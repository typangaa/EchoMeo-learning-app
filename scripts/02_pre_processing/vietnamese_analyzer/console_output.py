#!/usr/bin/env python3
"""
Console output module for Vietnamese vocabulary analysis.
Handles printing detailed statistics and summaries to console.
"""

def print_detailed_statistics(analysis, all_results):
    """Print comprehensive statistics to console."""
    
    print(f"\n{'='*60}")
    print(f"üìä COMPREHENSIVE VIETNAMESE VOCABULARY ANALYSIS")
    print(f"{'='*60}")
    
    # File processing summary
    successful_files = [r for r in all_results if r['success']]
    failed_files = [r for r in all_results if not r['success']]
    
    print(f"\nüìÅ FILE PROCESSING SUMMARY:")
    print(f"   Successfully processed: {len(successful_files)}/7 files")
    if failed_files:
        print(f"   Failed files:")
        for result in failed_files:
            print(f"      File {result['file_number']}: {result['error']}")
    
    # Vocabulary summary
    print(f"\nüìà VOCABULARY SUMMARY:")
    print(f"   Total vocabulary items: {analysis['total_vocabulary']:,}")
    print(f"   Unique words: {analysis['unique_words']:,}")
    print(f"   Duplicate entries: {analysis['duplicate_count']:,}")
    
    # Etymology analysis
    etymology = analysis['etymology_analysis']
    print(f"\nüèõÔ∏è ETYMOLOGY ANALYSIS:")
    for origin, count in etymology['etymology_distribution'].items():
        percentage = (count / analysis['total_vocabulary']) * 100
        print(f"   {origin.replace('_', ' ').title()}: {count:,} ({percentage:.1f}%)")
    
    # Chinese learner insights
    learning = analysis['learning_analysis']
    sino_ratio = learning['chinese_learner_insights']['sino_vietnamese_ratio']
    print(f"\nüá®üá≥ CHINESE LEARNER INSIGHTS:")
    print(f"   Sino-Vietnamese words: {learning['chinese_learner_insights']['sino_vietnamese_count']:,} ({sino_ratio:.1%})")
    print(f"   Native Vietnamese words: {learning['chinese_learner_insights']['native_vietnamese_count']:,} ({1-sino_ratio:.1%})")
    print(f"   Learning approach: {'Leverage Chinese knowledge' if sino_ratio > 0.5 else 'Mixed approach recommended'}")
    
    # Tone analysis
    tone = analysis['tone_analysis']
    print(f"\nüéµ TONE PATTERN ANALYSIS:")
    for tone_pattern, count in sorted(tone['tone_distribution'].items(), key=lambda x: x[1], reverse=True)[:10]:
        percentage = (count / analysis['total_vocabulary']) * 100
        print(f"   {tone_pattern}: {count:,} ({percentage:.1f}%)")
    
    # Learning difficulty distribution
    print(f"\nüìö LEARNING DIFFICULTY DISTRIBUTION:")
    for level, items in learning['learning_categories'].items():
        percentage = (len(items) / analysis['total_vocabulary']) * 100
        print(f"   {level.title()}: {len(items):,} ({percentage:.1f}%)")
    
    # Frequency analysis
    frequency = analysis['frequency_analysis']
    print(f"\nüìä FREQUENCY DISTRIBUTION:")
    for freq_range, count in frequency['frequency_ranges'].items():
        percentage = (count / analysis['total_vocabulary']) * 100
        print(f"   {freq_range.replace('_', ' ').title()}: {count:,} ({percentage:.1f}%)")
    
    # Syllable analysis
    syllable = analysis['syllable_analysis']
    print(f"\nüî§ SYLLABLE STRUCTURE ANALYSIS:")
    print(f"   Average syllables per word: {syllable['average_syllables']:.2f}")
    for syl_count, count in sorted(syllable['syllable_distribution'].items())[:5]:
        percentage = (count / analysis['total_vocabulary']) * 100
        print(f"   {syl_count} syllable(s): {count:,} ({percentage:.1f}%)")
    
    # POS analysis
    pos = analysis['pos_analysis']
    print(f"\nüìù PART-OF-SPEECH DISTRIBUTION:")
    total_pos_counts = sum(pos['pos_distribution'].values())
    for pos_type, count in sorted(pos['pos_distribution'].items(), key=lambda x: x[1], reverse=True)[:10]:
        percentage = (count / total_pos_counts) * 100
        print(f"   {pos_type}: {count:,} ({percentage:.1f}%)")
    
    # Regional variants
    regional = analysis['regional_analysis']
    print(f"\nüó∫Ô∏è REGIONAL VARIANT ANALYSIS:")
    for region_pair, count in regional['regional_differences'].items():
        print(f"   {region_pair.replace('_', '-').title()} differences: {count:,}")

def print_final_summary(analysis):
    """Print final summary with key insights."""
    
    print(f"\n{'='*60}")
    print(f"üéâ VIETNAMESE VOCABULARY ANALYSIS COMPLETED!")
    print(f"{'='*60}")
    
    learning = analysis['learning_analysis']
    sino_ratio = learning['chinese_learner_insights']['sino_vietnamese_ratio']
    
    print(f"üìä Key Results:")
    print(f"   ‚Ä¢ {analysis['unique_words']:,} unique Vietnamese words analyzed")
    print(f"   ‚Ä¢ {analysis['total_vocabulary']:,} total vocabulary items processed")
    print(f"   ‚Ä¢ {sino_ratio:.1%} Sino-Vietnamese words (great for Chinese learners!)")
    print(f"   ‚Ä¢ {len(learning['learning_categories']['beginner']):,} beginner-friendly words")
    
    print(f"\nüí° Learning Recommendations:")
    if sino_ratio > 0.6:
        print(f"   ‚Ä¢ High Sino-Vietnamese content - leverage your Chinese knowledge")
        print(f"   ‚Ä¢ Focus on character-meaning connections")
        print(f"   ‚Ä¢ Study Chu Nom characters for deeper understanding")
    elif sino_ratio > 0.3:
        print(f"   ‚Ä¢ Balanced approach - learn both Sino-Vietnamese and native patterns")
        print(f"   ‚Ä¢ Group words by etymology for efficient learning")
    else:
        print(f"   ‚Ä¢ Focus on native Vietnamese patterns and sounds")
        print(f"   ‚Ä¢ Pay special attention to tone patterns")
    
    # Top study priorities
    frequency = analysis['frequency_analysis']
    high_freq_count = frequency['frequency_ranges']['very_high'] + frequency['frequency_ranges']['high']
    print(f"   ‚Ä¢ Prioritize {high_freq_count:,} high-frequency words for immediate impact")
    
    print(f"\nüöÄ Next Steps:")
    print(f"   ‚Ä¢ Use generated word lists for vocabulary practice")
    print(f"   ‚Ä¢ Integrate Sino-Vietnamese words with Chinese character study")
    print(f"   ‚Ä¢ Focus on beginner words for quick progress")
    print(f"   ‚Ä¢ Practice tone patterns systematically")

def print_output_locations(output_dir):
    """Print information about output file locations."""
    
    print(f"\nüìÅ OUTPUT FILES CREATED:")
    print(f"   Main directory: {output_dir}")
    print(f"\n   üìÑ For App Integration:")
    print(f"      ‚Ä¢ vietnamese_words_list.json - Clean word list for React app")
    print(f"      ‚Ä¢ vietnamese_learning_data.json - Learning-focused data")
    
    print(f"\n   üìä For Analysis:")
    print(f"      ‚Ä¢ vietnamese_vocabulary_complete.json - Complete analysis")
    print(f"      ‚Ä¢ vietnamese_vocabulary_analysis.csv - Detailed data for Excel")
    print(f"      ‚Ä¢ vietnamese_learning_categories.csv - Learning difficulty data")
    
    print(f"\n   üìö For Study:")
    print(f"      ‚Ä¢ vietnamese_analysis_summary.txt - Human-readable summary")
    print(f"      ‚Ä¢ vietnamese_words_beginner.txt - Beginner word list")
    print(f"      ‚Ä¢ vietnamese_words_intermediate.txt - Intermediate word list")
    print(f"      ‚Ä¢ vietnamese_words_advanced.txt - Advanced word list")
    print(f"      ‚Ä¢ vietnamese_sino_vietnamese_words.txt - Chinese-origin words")

def print_usage_recommendations():
    """Print recommendations for using the analysis results."""
    
    print(f"\nüéØ USAGE RECOMMENDATIONS:")
    print(f"\n   For Vietnamese-Chinese Learning App:")
    print(f"      ‚Ä¢ Import vietnamese_words_list.json for vocabulary data")
    print(f"      ‚Ä¢ Use learning categories for difficulty grading")
    print(f"      ‚Ä¢ Prioritize Sino-Vietnamese words for Chinese speakers")
    print(f"      ‚Ä¢ Implement tone pattern practice based on frequency data")
    
    print(f"\n   For Curriculum Development:")
    print(f"      ‚Ä¢ Start with beginner-level high-frequency words")
    print(f"      ‚Ä¢ Group Sino-Vietnamese words with Chinese character lessons")
    print(f"      ‚Ä¢ Use regional variant data for pronunciation training")
    print(f"      ‚Ä¢ Apply frequency data for spaced repetition scheduling")
    
    print(f"\n   For Research & Analysis:")
    print(f"      ‚Ä¢ Use CSV files for statistical analysis")
    print(f"      ‚Ä¢ Reference etymology data for linguistic research")
    print(f"      ‚Ä¢ Analyze tone patterns for phonetic studies")

def print_error_summary(all_results):
    """Print summary of any errors encountered."""
    
    failed_results = [r for r in all_results if not r['success']]
    
    if failed_results:
        print(f"\n‚ö†Ô∏è  ERROR SUMMARY:")
        print(f"   {len(failed_results)} file(s) could not be processed:")
        
        for result in failed_results:
            print(f"      File {result['file_number']}: {result['error']}")
        
        print(f"\n   üí° Troubleshooting Tips:")
        print(f"      ‚Ä¢ Check that JSON files are valid UTF-8 encoded")
        print(f"      ‚Ä¢ Verify Vietnamese data structure matches expected format")
        print(f"      ‚Ä¢ Ensure 'vietnamese' field exists in all vocabulary items")
    else:
        print(f"\n‚úÖ All files processed successfully - no errors encountered!")
